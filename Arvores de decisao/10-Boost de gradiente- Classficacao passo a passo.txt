Prepare a sua booty, fudeu galerinha.

Para isso daki iremos nos utilizar do seguinte passa a passo para interpretacao.Ver imagen:(Passo a passo para classificacao)

E da seguinte database, ver imagen:(Data passa a passo)

Vamos comecar com o.

Input:

Data{(xi,yi)}**n i=1, ja foi explicado anteriormente mas vamos dar uma lembradinha. X sub i se refere a uma linha do dataset, y sub i se refere a classificacao dada. n e pq e variavel de acordo com o  numero de dados. E o i igual a 1 significa que o 1 sera o ponto de partida.

Agora temos que achar uma loss function diferenciavel, que funciona em classificacao. Para entender a loss function utilizada, vou me utilizar de um grafico.Ver imagen:(Grafico de probabilidade de amar ou nao amar)
Os detalhes do grafico sao auto explicativos.

Como antes, igual ao que e feito em regressao logistica. A gente pode calcular a log(likelihood) dos dados dada a probabilidade predita. Neste exemplo 0.67(2/3).

A log(likelihood dos dados observados dada a predicao inicial)= Ver imagen:(log(likelihood dos dados observados dada a predicao inicial))

Os p na imagen se referem, a probabilidade predita. Que seria 0.67.
Os y sub is se referem, aos valores observados da coluna ama trolls 2.
Para as pessoas que amam o filme, o valor de y sub i igual a 1, oque significa que a segunda porcao da formula sera nulificada.(Depois de (1-yi)). Para as pessoas que nao amam o filme, y sub i igual a 0 o que significa que o primeiro termo(antes de (1-yi)) sera nulificado. 
Aviso: ja que essa forma e um somataria ela se repete de acordo com o numero de datapoints.

Ver imagen:(Formula log summation resolvida).

Aviso: Quanto melhor uma predicao, maior a log(likelihood), e e por isso que quando a gente faz regressao logistica o objetivo e maximizar log(likelihood). Isso significa que a se a gente quiser usar log(likelihood) como uma loss function, onde os valores menores representam modelos mais bem treinados. A gente precisa multiplicar a log(likelihhod) por -1.

O que significa que na formula da imagen:((log(likelihood dos dados observados dada a predicao inicial))), poim-se um menos na frente e retira a somatoria, porque a gente geralmente faz datapoint por datapoint.

E para ficar mais facil de ler, substituimos y sub i por observado.

Ver imagen:(Semi simplificada formula log(likelihood) negativa individual).

Agora a gente precisa converter essa equacao negativa log(likelihood) para que seja uma funcao da predicao log(odds) ao inves de probabilidade de predicao(p). Basicamente temos que destruir os ps.

Existe uma serie de passos, mas so dois deles precisam ser explicados o resto e idiota. Ver imagen:(Conversao para log(odds))

O passo 3 na imagen, seria a substituicao [log(p)-log(1-p)]. Pelo, log(odds).  Que e possivel por causa da relacao entre p e log(odds).
(log(p//1-p)=log(odds))

O passo 4 e muito semelhante, so que e outra relacao. De substituicao. Ver imagen:(Relacao 1-p com log(odds)).

E boom chegamos na nossa loss function.

Agora so precisamos comprovar que ela e diferenciavel
Pegamos a derivada da funcao do passo 5 nos utilizamos da chain rule, para resolver (+log(1+e**log(odds)) e notamos que temos dois resultados um com probabilidade e outro com log(odds). Porque consiguimos converter elas entre si usando a funcao logit.Ver imagen:(Derivada da loss function resolvida)

E acabamos input

Passo 1:

Como antes temos que inicializar o modelo com algum tipo de predicao.
E exatamente como no modelo de regressao, precisamos encontrar a melhor predicao inicial. 
Lembrete:L(yi,y(gamma)), e a loss function. O gamma nesse caso, seria ao log(odds) na loss function.(-Observado*log(odds)+log(1+e**log(odds))).
A somatoria significa que temos que adicionar as losses functions de todos datapoints. 
O argmin sobre y(gamma), significa que precisamos encontrar o log(odds) tambem gamma, que minimiza essa funcao.

A primeira coisa que fazemos e retirar a derivado de cada datapoint, como respeito ao log(odds). Depois substituimos, os log(odds) dentro da funcao (atraves da logit function) pela probabilidade e igualamos as derivadas a  0.Ver imagen:(Resulacao da derivada para achar o ponto otimal do log odd) 
E resolvemos obtendo uma probabilidade de predicao(p).
Retornamos para funcao log(odds) essa probabilidade (atraves de log(odds)=log(p/1-p). 
E achamos o log(odds) que minimiza a funcao gamma.No exemplo, ele e igual log(odds)=log(2/1)=0.69. Achamos o ponto otimal.
E pronto inicializamos o modelo, com o valor constante. Ou em outras palavra, criamos o leaf node que prediz o log(odds) que alguem vai amar trolls 2.

Passo 2:

O passo 2 que nem no gradient boost para regressao, sao os passos de construcao da arvore. E definimos o m = 1(primeira arvore) e comecamos dae. 

A) 
Na parte a calculamos os pseudo residuos de cada datapoint, com essa coisa feia aqui.
Ver imagem:(Parte feia pra caralho passo a). Isso nao e nada mais, do que a derivada da loss function com respeito aos log(odds) preditos. O que ja foi calculado.(-Observado+(e**log(odds)//1+e**log(odds)).
Aquele sinal de - antes daquele baguiu feio pra caralho. Origina isso:(Observado-(e**log(odds)//1+e**log(odds)).
Nao esquece que podemos trocar o valor depois de Observado- na formula acima, pela predita probabilidade(p).(Observado-p). O que resulta nos pseudo residuos.
Os F(x)=Fm-1(x), significa para por o log(odds) de predicao mais recente(ponto otimal achado anteriormente).
No exemplo, o F0(x)=log(2/1)=0.69. Podemos converter isso na probabilidade predita. p=0.67. Atraves denovo da funcao logistic.
Agora podemos computar, os pseudo residuos para cada datapoint.
(Observado-0,67)
Lembrete: A probabilidade predita varia no futura com adicao do learning rate * contribuicao do valor de output da arvore. 
Ri,m. i=Numero do datapoint, m qual arvore estamos construindo. 
Ver imagen:(Residuos da diferenca entre observado e p da primeira arvore)

B)
Parte b e parte de construcao de uma arvore residual de regressao, que tera como base os outros fatores do dataset(gosta de pipoca, idade, etc) focada em adivinhar em adivinhar o residuo utilizado.
E tambem a parte que criamos os labels de nossas regioes terminais(leaf nodes).
Lembrete: j=leaf node do residuo avaliado, m arvore atual.
Ver imagen:(Parte b feita)

C)
E nessa parte que calculamos o valor de output, para a nova arvore
Essa parte calcula que calculamos o output value. Tem muita matematica excessivamente complexo

D) 
E quando a gente faz a predicao para cada exemplo
Fm(x) no exemplo vira F1(x)
Fm-1(x), significa a predicao anterior. No exemplo, F0(x)(output do leaf node),log(2/1). Se tivesse uma arvore residual seria, o log(2/1)+learning rate*valor de output do dado depois de passar na arvore.
Aquele v estranho significa learing rate, a se refere a adicao do output value de uma nova arvore residual criada.
Depois desse passo consiguimos o log odds preditivo para o dado.

Passo 3:

Seria a parte em que a gente pega todas as arvores residuais e leaf nodes criados, pega um novo datapoint qualquer. Passa ele pelas as arvores multiplicados pelos learning rates. Soma todos os valores de output, e obtem-se um log(odds).Ver imagen(Predicao final de classificacao log(odds))
Converte esse log(odds) em probabilidade e boom, voce tem um valor. Se esse valor passar do threshold classifique ele, como positivo senao negativo.

